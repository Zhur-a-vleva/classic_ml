{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "EQUr4xboqg-x"
      },
      "source": [
        "# ANN in Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvB13hNvqg-4"
      },
      "outputs": [],
      "source": [
        "!pip3 install torch\n",
        "!pip3 install torchvision\n",
        "!pip3 install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNnXYkKpqg-5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def sigmoid_activation(x):\n",
        "    \"\"\" Sigmoid activation function\n",
        "\n",
        "        Arguments\n",
        "        ---------\n",
        "        x: torch.Tensor\n",
        "    \"\"\"\n",
        "    return 1/(1+torch.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YgLoi2Uqg-6"
      },
      "outputs": [],
      "source": [
        "### Generate some data and set the random seed so things are predictable\n",
        "torch.manual_seed(7)\n",
        "\n",
        "# Input features, 5 random normal variables\n",
        "x = torch.randn((1, 5))\n",
        "\n",
        "# True weights for our data, random normal variables again\n",
        "weights = torch.randn_like(x)\n",
        "\n",
        "# True bias term\n",
        "bias = torch.randn((1, 1))\n",
        "\n",
        "print(f\"Input vector for neuron: {x}\")\n",
        "print(f\"Weights of input: {weights}\")\n",
        "print(f\"Bias : {bias}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHzGMhceqg-7"
      },
      "outputs": [],
      "source": [
        "# Compute the output here\n",
        "y = sigmoid_activation(torch.sum(x * weights) + bias)\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY5mbjYOqg-7"
      },
      "source": [
        "#### Matrix multiplication in Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isse5n8Cqg-7"
      },
      "outputs": [],
      "source": [
        "print(f\"Shape of weight matrix: {weights.shape}\")\n",
        "print(f\"Shape of input vector: {x.shape}\")\n",
        "\n",
        "y = sigmoid_activation(torch.mm(x, weights.view(5,1)) + bias)\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPe6_KSeqg-8"
      },
      "outputs": [],
      "source": [
        "### Generate some data\n",
        "torch.manual_seed(7)\n",
        "\n",
        "# Features are 3 random normal variables\n",
        "features = torch.randn((1, 3))\n",
        "\n",
        "# Define the size of each layer in our network\n",
        "\n",
        "# Number of input units, must match number of input features\n",
        "n_input = features.shape[1]\n",
        "# Number of hidden units\n",
        "n_hidden = 2\n",
        "# Number of output units\n",
        "n_output = 1\n",
        "\n",
        "# Weights from inputs to hidden layer\n",
        "W1 = torch.randn(n_input, n_hidden)\n",
        "# Weights from hidden layer to output layer\n",
        "W2 = torch.randn(n_hidden, n_output)\n",
        "\n",
        "# Bias terms for hidden and output layers\n",
        "B1 = torch.randn((1, n_hidden))\n",
        "B2 = torch.randn((1, n_output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOlKEQntqg-8"
      },
      "outputs": [],
      "source": [
        "h = sigmoid_activation(torch.mm(features, W1) + B1)\n",
        "output = sigmoid_activation(torch.mm(h, W2) + B2)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXQJyu5Tqg-8"
      },
      "source": [
        "### Pytorch Autograd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbVbwo4Iqg-8"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor(5.0, requires_grad=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8lKwO4Uqg-9"
      },
      "source": [
        "Let's consider a function of x:  $$f(x) = x^2 + 2x + 1$$\n",
        "\n",
        "The following code will compute and **accumulate** the gradient w.r.t $x$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lo2FbD4eqg-9"
      },
      "outputs": [],
      "source": [
        "# Compute function f(x) = x^2 + 2x + 1\n",
        "z = x ** 2 + 2*x + 1\n",
        "print(z, z.requires_grad)\n",
        "\n",
        "print(f\"Gradient on tensor before backward(): {x.grad}\")\n",
        "# Compute and propagate the gradient\n",
        "z.backward()\n",
        "print(f\"Gradient on tensor after backward(): {x.grad}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMx4snxKqg-9"
      },
      "outputs": [],
      "source": [
        "x.grad = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6ymlhAwqg--"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    x = torch.tensor(5.0, requires_grad=True)\n",
        "    print(f\"x.requires_grad {x.requires_grad}\")\n",
        "\n",
        "    z_no_grad = x ** 2 + 2*x + 1\n",
        "\n",
        "    # Even if x requires gradient, we cannot compute the gradient of function z_no_grad inside this block\n",
        "    print(f\"Value of z: {z_no_grad}, Requires grad?: {z_no_grad.requires_grad}\")\n",
        "    # z.backward()  will trigger an error, because no gradient is tracked"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S86tdSwtqg--"
      },
      "source": [
        "### Tensor to numpy array and vice-versa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8URfGjLVqg--"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "a = np.random.rand(4,3)\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mC4wQk7Cqg--"
      },
      "outputs": [],
      "source": [
        "b = torch.from_numpy(a)\n",
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UykGNc6_qg--"
      },
      "outputs": [],
      "source": [
        "b.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "mMlVCJVQqg-_"
      },
      "source": [
        "\n",
        "## Model Design in Pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "46DYAcpXqg-_"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 32\n",
        "test_batch_size = 100\n",
        "\n",
        "data_transformations = transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           # Normalize an image with mean 0.1307 and standard deviation 0.3081.\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ])\n",
        "\n",
        "mnist_train = datasets.MNIST('../data', train=True, download=True,\n",
        "                           transform=data_transformations)\n",
        "mnist_test = datasets.MNIST('../data', train=False,\n",
        "                            transform=data_transformations)\n",
        "\n",
        "train_loader = DataLoader(mnist_train,\n",
        "                          batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(mnist_test,\n",
        "                         batch_size=test_batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSEm7F8Eqg_A"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Get the next batch from loader\n",
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "print(f\"Label={labels[0]}\")\n",
        "plt.imshow(images[0].reshape(28,28), cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "w2qDCxIMqg_A"
      },
      "source": [
        "### Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVN8JHk7qg_A"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torch import sigmoid\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "\n",
        "# Definition of the very simple network with 1 hidden layer\n",
        "class ToyNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        # Invoke the parent's constructor\n",
        "        super(ToyNet, self).__init__()\n",
        "        # nn implements feedworward layer as nn.Linear(a, b),\n",
        "        # where a, b - input and output dims of weight matrix.\n",
        "        # Bias is included by default.\n",
        "        self.hidden = nn.Linear(3, 2)\n",
        "        self.output = nn.Linear(2, 1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = sigmoid(self.hidden(x))\n",
        "        x = self.output(x)\n",
        "        return sigmoid(x)\n",
        "\n",
        "\n",
        "model = ToyNet().to(device)\n",
        "\n",
        "print(f\"ToyNet model architecture:\\n {model}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "toy_x = torch.randn((1,3))\n",
        "print(f\"Prediction of {toy_x} : {model(toy_x)}\")\n",
        "print(f\"Prediction of {toy_x} by .forward : {model.forward(toy_x)}\")\n",
        "toy_xs = torch.randn((4,3))\n",
        "print(f\"Prediction on batch: {model(toy_xs)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qZL947glqg_B"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Shape of 1st hidden linear layer: (input_array_size, 256)\n",
        "        self.hidden1 = nn.Linear(28*28, 256)\n",
        "        # (256, 100)\n",
        "        self.hidden2 = nn.Linear(256, 100)\n",
        "        # (100, 10)\n",
        "        self.output = nn.Linear(100, 10)\n",
        "\n",
        "    # The batch x is of size (batch, 28 * 28)\n",
        "    def forward(self, x):\n",
        "        # Flatten of 2D image to 1D array\n",
        "        x = x.view(-1, 28*28)\n",
        "        # Complete the flow in hidden layers and output\n",
        "        x = F.relu(self.hidden1(x))\n",
        "        x = F.relu(self.hidden2(x))\n",
        "        x = self.output(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "model = Net().to(device)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "KgnJC0dgqg_B"
      },
      "source": [
        "### Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Y3rPfzT_qg_B"
      },
      "outputs": [],
      "source": [
        "# Number of iterations over the whole data set\n",
        "epochs = 5\n",
        "# Learning rate for Stochastic Gradient Descent\n",
        "lr = 0.01\n",
        "# SGD parameter to accelerate the optimization\n",
        "momentum = 0.5\n",
        "# Loss function - cross entropy, the multiclass variant\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1BQzAdzqqg_C"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train( model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    # A wrapper over data loader to show progress bar\n",
        "    bar = tqdm(train_loader)\n",
        "    iteration = 0\n",
        "    overall_loss = 0\n",
        "    for data, target in bar:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        # To avoid an accumulation of gradients\n",
        "        optimizer.zero_grad()\n",
        "        # Prediction\n",
        "        output = model(data)\n",
        "        # Error between prediction and ground truth\n",
        "        loss = criterion(output, target)\n",
        "        # Compute gradient\n",
        "        loss.backward()\n",
        "        # Update params of model\n",
        "        optimizer.step()\n",
        "\n",
        "        iteration += 1\n",
        "        overall_loss += loss.item()\n",
        "        bar.set_postfix({\"Loss\": format(overall_loss/iteration, '.6f')})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "eedWQR_Fqg_C"
      },
      "outputs": [],
      "source": [
        "def test( model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            # sum up batch loss\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print(f\"Test set: Average loss: {test_loss}, Accuracy: {100. * correct / len(test_loader.dataset)} \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "MNFXx8zIqg_C"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}